---
title: "Predicting Raw COMPAS scores"
output: html_notebook
---

```{r}
### Install xgboost from Github (only run once)
#install.packages("drat", repos="https://cran.rstudio.com")
#drat:::addRepo("dmlc")
#install.packages("xgboost", repos="http://dmlc.ml/drat/", type = "source")
```

```{r, message=FALSE,warning=FALSE}
library(xgboost)
library(readr)
library(dplyr)
```

## Violent Recidivism

```{r}
### Prepare training data (Version A input)
feat = read_csv("features.csv")

## Select features and round count features
train_violent = feat %>%
  transmute(p_current_age,
            p_age_first_offense,
            p_juv_fel_count = pmin(p_juv_fel_count,2),
            p_felprop_violarrest = pmin(p_felprop_violarrest,5),
            p_murder_arrest = pmin(p_murder_arrest,3),
            p_felassault_arrest = pmin(p_felassault_arrest,3),
            p_misdemassault_arrest = pmin(p_misdemassault_arrest,3),
            p_famviol_arrest = pmin(p_famviol_arrest,3),
            p_sex_arrest = pmin(p_sex_arrest,3),
            p_weapons_arrest = pmin(p_weapons_arrest,3),
            Risk)

## Format for xgboost
train_violent_xgb = xgb.DMatrix(
 "data" = train_violent %>% select(-p_violence_raw) %>% as.matrix(),
 "label" = train_violent %>% select(p_violence_raw) %>% as.matrix()
)
```

```{r}
### Prepare training data (Version B input)
feat = read_csv("features_vB.csv")

## Select features and round count features
train_violent = feat %>%
  rename(p_violence_raw = "Risk of Violence_raw_score") %>%
  #filter(!is.na(first_offense_date) & !is.na(current_offense_date)) %>%
  transmute(p_current_age,
            p_age_first_offense,
            p_juv_fel_count = pmin(p_juv_fel_count,2),
            p_felprop_violarrest = pmin(p_felprop_violarrest,5),
            p_murder_arrest = pmin(p_murder_arrest,3),
            p_felassault_arrest = pmin(p_felassault_arrest,3),
            p_misdemassault_arrest = pmin(p_misdemassault_arrest,3),
            p_famviol_arrest = pmin(p_famviol_arrest,3),
            p_sex_arrest = pmin(p_sex_arrest,3),
            p_weapons_arrest = pmin(p_weapons_arrest,3),
            p_violence_raw)

## Format for xgboost
train_violent_xgb = xgb.DMatrix(
 "data" = train_violent %>% select(-p_violence_raw) %>% as.matrix(),
 "label" = train_violent %>% select(p_violence_raw) %>% as.matrix()
)
```

```{r}
### Grid search over parameters
set.seed(3628)

## Set parameters (each combination will be run)
param <- list(objective = "reg:linear",
              eval_metric = "rmse",
              eta = c(.1,.3),
              gamma = c(.1,.5), 
              max_depth = c(2,5,10),
              min_child_weight = c(1,10),
              subsample = 1,
              colsample_bytree = 1
)
param_df = expand.grid(param) # Each row is a set of parameters to be cross validated
n_param = nrow(param_df)

## Allocate space for performance statistics (and set seeds)
performance = data.frame(
  i_param = 1:n_param,
  seed = sample.int(10000, n_param),
  matrix(NA,nrow=2,ncol=5,
         dimnames=list(NULL,
                       c("iter","train_rmse_mean","train_rmse_std","test_rmse_mean","test_rmse_std"))))
col_eval_log = 3:7 # Adjust manually. Column index in performance of evaluation_log output from xgb.cv

## Loop through the different parameters sets
for (i_param in 1:n_param) {
  cat("Training on parameter set",i_param,"of",n_param,"\n")
  
  set.seed(performance$seed[i_param])
  
  mdcv = xgb.cv(data=train_violent_xgb, 
                params = list(param_df[i_param,])[[1]], 
                nthread=6, 
                nfold=5, 
                nrounds=1000,
                verbose = FALSE, 
                early_stopping_rounds=10, 
                maximize=FALSE)
  
  performance[i_param,col_eval_log] = mdcv$evaluation_log[mdcv$best_iteration,]
}

## Train on best parameters using best number of rounds
i_param_best = performance$i_param[which.min(performance$test_rmse_mean)]
print(t(param_df[i_param_best,])) #Prints the best parameters

set.seed(performance$seed[i_param_best])

md = xgb.train(data=train_violent_xgb, 
               params=list(param_df[i_param_best,])[[1]], 
               nrounds=performance$iter[i_param_best], 
               nthread=6)
```


```{r}
## Plot predictions
pred = predict(md, newdata=train_violent_xgb)
actual = train_violent$p_violence_raw

error_violent = pred-actual

rmse = sqrt(mean((pred - actual)^2))

axis_min = min(min(pred),min(actual))
axis_max = max(max(pred),max(actual))

par(pty="s")
plot(actual, pred,
     xlab="Raw Violence Score",
     ylab="Prediction",
     main=paste("RMSE:",round(rmse,2)),
     xlim=c(axis_min,axis_max),
     ylim=c(axis_min,axis_max))
abline(a=0,b=1,col='red')
```

```{r}
### Variable importance
importance_matrix <- xgb.importance(model = md)
xgb.plot.importance(importance_matrix = importance_matrix)
```

## General Recidivism

```{r}
### Prepare training data

## Select features and round count features
train_general = feat %>%
  transmute(p_age,
            p_age_first_offense,
            p_narreest = p_felony_count_person+p_misdem_count_person+p_juv_fel_count, # Is this charges or arrests?
            p_jail_visits_30 = pmin(p_jail_visits_30,5),
            p_prison_visits = pmin(p_prison_visits,5),
            p_recid_raw)

## Format for xgboost
train_general_xgb = xgb.DMatrix(
 "data" = train_general %>% select(-p_recid_raw) %>% as.matrix(),
 "label" = train_general %>% select(p_recid_raw) %>% as.matrix()
)
```

```{r}
### Grid search over parameters
set.seed(3628)

## Set parameters (each combination will be run)
param <- list(objective = "reg:linear",
              eval_metric = "rmse",
              eta = c(.1,.3),
              gamma = c(.1,.5), 
              max_depth = c(2,5,10),
              min_child_weight = c(1,10),
              subsample = 1,
              colsample_bytree = 1
)
param_df = expand.grid(param) # Each row is a set of parameters to be cross validated
n_param = nrow(param_df)

## Allocate space for performance statistics (and set seeds)
performance = data.frame(
  i_param = 1:n_param,
  seed = sample.int(10000, n_param),
  matrix(NA,nrow=2,ncol=5,
         dimnames=list(NULL,
                       c("iter","train_rmse_mean","train_rmse_std","test_rmse_mean","test_rmse_std"))))
col_eval_log = 3:7 # Adjust manually. Column index in performance of evaluation_log output from xgb.cv

## Loop through the different parameters sets
for (i_param in 1:n_param) {
  cat("Training on parameter set",i_param,"of",n_param,"\n")
  
  set.seed(performance$seed[i_param])
  
  mdcv = xgb.cv(data=train_general_xgb, 
                params = list(param_df[i_param,])[[1]], 
                nthread=6, 
                nfold=5, 
                nrounds=1000,
                verbose = FALSE, 
                early_stopping_rounds=10, 
                maximize=FALSE)
  
  performance[i_param,col_eval_log] = mdcv$evaluation_log[mdcv$best_iteration,]
}

## Train on best parameters using best number of rounds
i_param_best = performance$i_param[which.min(performance$test_rmse_mean)]
print(t(param_df[i_param_best,])) #Prints the best parameters

set.seed(performance$seed[i_param_best])

md = xgb.train(data=train_general_xgb, 
               params=list(param_df[i_param_best,])[[1]], 
               nrounds=performance$iter[i_param_best], 
               nthread=6)
```


```{r}
## Plot predictions
pred = predict(md, newdata=train_general_xgb)
actual = train_general$p_recid_raw

rmse = sqrt(mean((pred - actual)^2))

error_general = pred-actual

axis_min = min(min(pred),min(actual))
axis_max = max(max(pred),max(actual))

par(pty="s")
plot(actual, pred,
     xlab="Raw Violence Score",
     ylab="Prediction",
     main=paste("RMSE:",round(rmse,2)),
     xlim=c(axis_min,axis_max),
     ylim=c(axis_min,axis_max))
abline(a=0,b=1,col='red')
```


```{r}
train_general %>%
  mutate(pred = predict(md, newdata=train_general_xgb),
         error = pred - p_recid_raw,
         decile = floor(p_age_first_offense/10)*10) %>%
  group_by(decile) %>%
  summarize(age_error=mean(abs(error)),
            sample_size=n())
```


```{r}
### Variable importance
importance_matrix <- xgb.importance(model = md)
xgb.plot.importance(importance_matrix = importance_matrix)
```

```{r}
plot(error_general, error_violent)
```

