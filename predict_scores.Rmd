---
title: "Predicting Raw COMPAS scores"
output: html_notebook
---

```{r}
### Install xgboost from Github (only run once)
#install.packages("drat", repos="https://cran.rstudio.com")
#drat:::addRepo("dmlc")
#install.packages("xgboost", repos="http://dmlc.ml/drat/", type = "source")
```

```{r, message=FALSE,warning=FALSE}
library(xgboost)
library(readr)
library(dplyr)
```

## Violent Recidivism

```{r}
### Prepare training data (Version A input)
feat = read_csv("features.csv")

## Select features and round count features
train_violent = feat %>%
  transmute(p_current_age,
            p_age_first_offense,
            p_juv_fel_count = pmin(p_juv_fel_count,2),
            p_felprop_violarrest = pmin(p_felprop_violarrest,5),
            p_murder_arrest = pmin(p_murder_arrest,3),
            p_felassault_arrest = pmin(p_felassault_arrest,3),
            p_misdemassault_arrest = pmin(p_misdemassault_arrest,3),
            p_famviol_arrest = pmin(p_famviol_arrest,3),
            p_sex_arrest = pmin(p_sex_arrest,3),
            p_weapons_arrest = pmin(p_weapons_arrest,3),
            Risk)

## Format for xgboost
train_violent_xgb = xgb.DMatrix(
 "data" = train_violent %>% select(-p_violence_raw) %>% as.matrix(),
 "label" = train_violent %>% select(p_violence_raw) %>% as.matrix()
)
```

```{r}
### Prepare training data (Version B input)
feat = read_csv("features_vB.csv")

feat = feat %>%
  filter(!is.na(first_offense_date) & !is.na(current_offense_date))

## Select features and round count features
train_violent = feat %>%
  rename(p_violence_raw = "Risk of Violence_raw_score") %>%
  transmute(p_current_age,
            p_age_first_offense,
            p_juv_fel_count = pmin(p_juv_fel_count,2),
            p_felprop_violarrest = pmin(p_felprop_violarrest,5),
            p_murder_arrest = pmin(p_murder_arrest,3),
            p_felassault_arrest = pmin(p_felassault_arrest,3),
            p_misdemassault_arrest = pmin(p_misdemassault_arrest,3),
            #p_famviol_arrest = pmin(p_famviol_arrest,3),
            p_sex_arrest = pmin(p_sex_arrest,3),
            p_weapons_arrest = pmin(p_weapons_arrest,3),
            p_n_on_probation = pmin(p_n_on_probation,5),
            p_current_on_probation = pmin(p_current_on_probation,5),
            p_prob_revoke = pmin(p_prob_revoke,5),
            p_violence_raw)

## Format for xgboost
train_violent_xgb = xgb.DMatrix(
 "data" = train_violent %>% select(-p_violence_raw) %>% as.matrix(),
 "label" = train_violent %>% select(p_violence_raw) %>% as.matrix()
)
```

```{r}
### Linear model

md_lm = lm(p_violence_raw ~ . + I(p_current_age^2), data=train_violent)

pred = predict(md_lm, newdata=train_violent)
actual = train_violent$p_violence_raw

rmse = sqrt(mean((pred - actual)^2))

axis_min = min(min(pred),min(actual))
axis_max = max(max(pred),max(actual))

par(pty="s")
plot(actual, pred,
     xlab="Raw Violence Score",
     ylab="Prediction",
     main=paste("RMSE:",round(rmse,2)),
     xlim=c(axis_min,axis_max),
     ylim=c(axis_min,axis_max))
abline(a=0,b=1,col='red')
```




```{r}
### Grid search over parameters
set.seed(3628)

## Set parameters (each combination will be run)
param <- list(objective = "reg:linear",
              eval_metric = "rmse",
              eta = c(.05,.1),
              gamma = c(.5, 1), 
              max_depth = c(2,5),
              min_child_weight = c(5,10),
              subsample = c(1),
              colsample_bytree = c(1)
)
param_df = expand.grid(param) # Each row is a set of parameters to be cross validated
n_param = nrow(param_df)

## Allocate space for performance statistics (and set seeds)
performance = data.frame(
  i_param = 1:n_param,
  seed = sample.int(10000, n_param),
  matrix(NA,nrow=2,ncol=5,
         dimnames=list(NULL,
                       c("iter","train_rmse_mean","train_rmse_std","test_rmse_mean","test_rmse_std"))))
col_eval_log = 3:7 # Adjust manually. Column index in performance of evaluation_log output from xgb.cv

## Loop through the different parameters sets
for (i_param in 1:n_param) {
  cat("Training on parameter set",i_param,"of",n_param,"\n")
  
  set.seed(performance$seed[i_param])
  
  mdcv = xgb.cv(data=train_violent_xgb, 
                params = list(param_df[i_param,])[[1]], 
                nthread=6, 
                nfold=5, 
                nrounds=5000,
                verbose = FALSE, 
                early_stopping_rounds=100, 
                maximize=FALSE)
  
  performance[i_param,col_eval_log] = mdcv$evaluation_log[mdcv$best_iteration,]
}

## Train on best parameters using best number of rounds
i_param_best = performance$i_param[which.min(performance$test_rmse_mean)]
print(t(param_df[i_param_best,])) #Prints the best parameters

set.seed(performance$seed[i_param_best])

md = xgb.train(data=train_violent_xgb, 
               params=list(param_df[i_param_best,])[[1]], 
               nrounds=performance$iter[i_param_best], 
               nthread=6)
```

```{r}
## Avg test error by different hyperparameter values

res = cbind(param_df, performance)

res %>%
  group_by(eta) %>%
  summarize(mean(test_rmse_mean))

res %>%
  group_by(gamma) %>%
  summarize(mean(test_rmse_mean))

res %>%
  group_by(max_depth) %>%
  summarize(mean(test_rmse_mean))

res %>%
  group_by(min_child_weight) %>%
  summarize(mean(test_rmse_mean))

res %>%
  group_by(subsample) %>%
  summarize(mean(test_rmse_mean))

res %>%
  group_by(colsample_bytree) %>%
  summarize(mean(test_rmse_mean))
```



```{r}
## Plot predictions
pred = predict(md, newdata=train_violent_xgb)
actual = train_violent$p_violence_raw
error = pred-actual

rmse = sqrt(mean((pred - actual)^2))

axis_min = min(min(pred),min(actual))
axis_max = max(max(pred),max(actual))

par(pty="s")
plot(actual, pred,
     xlab="Raw Violence Score",
     ylab="Prediction",
     main=paste("RMSE:",round(rmse,2)),
     xlim=c(axis_min,axis_max),
     ylim=c(axis_min,axis_max))
abline(a=0,b=1,col='red')
```

```{r}
res_violent = feat %>%
  left_join(select(people_df, person_id, name, sex, race), by = "person_id")

res_violent$pred = pred
res_violent$actual = actual
res_violent$error = error
res_violent$abs_error = abs(error)
res_violent$overest = pred > actual
```

```{r}
print(paste("Fraction overestimated =",round(mean(res_violent$overest),2)))
print(paste("Ratio African-American / Caucasian =",round(sum(res_violent$race=="African-American") / sum(res_violent$race=="Caucasian"),2)))
print(paste("Ratio Men / Women =",round(sum(res_violent$sex=="Male") / sum(res_violent$sex=="Female"),2)))

res_violent %>%
  group_by(sex) %>%
  summarize(sample_size=n(),mean(abs_error), frac_overest = mean(overest))

res_violent %>%
  group_by(race) %>%
  summarize(sample_size=n(),mean(abs_error), frac_overest = mean(overest))

res_violent %>%
  mutate(age_decile = floor(p_current_age/10)*10) %>%
  group_by(age_decile) %>%
  summarize(sample_size=n(),mean(abs_error), frac_overest = mean(overest))

res_violent %>%
  group_by(p_charge) %>%
  summarize(sample_size=n(),mean(abs_error), frac_overest = mean(overest))
```

```{r}
### People with largest errors
thresh = quantile(res_violent$abs_error, probs = .90)
res_violent_worst = res_violent %>%
  filter(abs_error > thresh)

print(paste("Fraction overestimated =",round(mean(res_violent_worst$overest),2)))
print(paste("Ratio African-American / Caucasian =",round(sum(res_violent_worst$race=="African-American") / sum(res_violent_worst$race=="Caucasian"),2)))
print(paste("Ratio Men / Women =",round(sum(res_violent_worst$sex=="Male") / sum(res_violent_worst$sex=="Female"),2)))

res_violent_worst %>%
  group_by(sex) %>%
  summarize(sample_size=n(),mean(abs_error), frac_overest = mean(overest))

res_violent_worst %>%
  group_by(race) %>%
  summarize(sample_size=n(),mean(abs_error), frac_overest = mean(overest))

res_violent_worst %>%
  mutate(age_decile = floor(p_current_age/10)*10) %>%
  group_by(age_decile) %>%
  summarize(sample_size=n(),mean(abs_error), frac_overest = mean(overest))

res_violent_worst %>%
  group_by(p_charge) %>%
  summarize(sample_size=n(),mean(abs_error), frac_overest = mean(overest))
```


```{r}
### Variable importance
importance_matrix <- xgb.importance(model = md)
xgb.plot.importance(importance_matrix = importance_matrix)
```

## General Recidivism

```{r}
### Prepare training data (Version B input)
feat = read_csv("features_vB.csv")

feat = feat %>%
  filter(!is.na(first_offense_date) & !is.na(current_offense_date))

## Select features and round count features
train_general = feat %>%
  rename(p_recid_raw = "Risk of Recidivism_raw_score") %>%
  transmute(p_current_age,
            p_age_first_offense,
            #p_charge,
            p_arrest,
            p_jail30 = pmin(p_jail30,5),
            #p_prison30 = pmin(p_prison30,5),
            p_prison = pmin(p_prison,5),
            p_probation = pmin(p_probation,5),
            p_recid_raw)

train_general_age = train_general %>%
  select(p_current_age, p_age_first_offense, p_recid_raw)

## Format for xgboost
train_general_xgb = xgb.DMatrix(
 "data" = train_general %>% select(-p_recid_raw) %>% as.matrix(),
 "label" = train_general %>% select(p_recid_raw) %>% as.matrix()
)

train_general_age_xgb = xgb.DMatrix(
 "data" = train_general_age %>% select(-p_recid_raw) %>% as.matrix(),
 "label" = train_general_age %>% select(p_recid_raw) %>% as.matrix()
)
```

```{r}
### Grid search over parameters
set.seed(3628)

## Set parameters (each combination will be run)
param <- list(objective = "reg:linear",
              eval_metric = "rmse",
              eta = c(.05,.1),
              gamma = c(.5, 1), 
              max_depth = c(2,5),
              min_child_weight = c(5,10),
              subsample = c(1),
              colsample_bytree = c(1)
)
param_df = expand.grid(param) # Each row is a set of parameters to be cross validated
n_param = nrow(param_df)

## Allocate space for performance statistics (and set seeds)
performance = data.frame(
  i_param = 1:n_param,
  seed = sample.int(10000, n_param),
  matrix(NA,nrow=2,ncol=5,
         dimnames=list(NULL,
                       c("iter","train_rmse_mean","train_rmse_std","test_rmse_mean","test_rmse_std"))))
col_eval_log = 3:7 # Adjust manually. Column index in performance of evaluation_log output from xgb.cv

## Loop through the different parameters sets
for (i_param in 1:n_param) {
  cat("Training on parameter set",i_param,"of",n_param,"\n")
  
  set.seed(performance$seed[i_param])
  
  mdcv = xgb.cv(data=train_general_xgb, 
                params = list(param_df[i_param,])[[1]], 
                nthread=6, 
                nfold=5, 
                nrounds=1000,
                verbose = FALSE, 
                early_stopping_rounds=10, 
                maximize=FALSE)
  
  performance[i_param,col_eval_log] = mdcv$evaluation_log[mdcv$best_iteration,]
}

## Train on best parameters using best number of rounds
i_param_best = performance$i_param[which.min(performance$test_rmse_mean)]
print(t(param_df[i_param_best,])) #Prints the best parameters

set.seed(performance$seed[i_param_best])

md_general = xgb.train(data=train_general_xgb, 
               params=list(param_df[i_param_best,])[[1]], 
               nrounds=performance$iter[i_param_best], 
               nthread=6)
```


```{r}
## Plot predictions
pred = predict(md_general, newdata=train_general_xgb)
actual = train_general$p_recid_raw
error = pred-actual

rmse = sqrt(mean((pred - actual)^2))

axis_min = min(min(pred),min(actual))
axis_max = max(max(pred),max(actual))

par(pty="s")
plot(actual, pred,
     xlab="Raw Violence Score",
     ylab="Prediction",
     main=paste("RMSE:",round(rmse,2)),
     xlim=c(axis_min,axis_max),
     ylim=c(axis_min,axis_max))
abline(a=0,b=1,col='red')
```


```{r}
res_general = feat %>%
  left_join(select(people_df, person_id, name, sex, race), by = "person_id")

res_general$pred = pred
res_general$actual = actual
res_general$error = error
res_general$abs_error = abs(error)
res_general$overest = pred > actual
```

```{r}
print(paste("Fraction overestimated =",round(mean(res_general$overest),2)))
print(paste("Ratio African-American / Caucasian =",round(sum(res_general$race=="African-American") / sum(res_general$race=="Caucasian"),2)))
print(paste("Ratio Men / Women =",round(sum(res_general$sex=="Male") / sum(res_general$sex=="Female"),2)))

res_general %>%
  group_by(sex) %>%
  summarize(sample_size=n(),mean(abs_error), frac_overest = mean(overest))

res_general %>%
  group_by(race) %>%
  summarize(sample_size=n(),mean(abs_error), frac_overest = mean(overest))

res_general %>%
  mutate(age_decile = floor(p_current_age/10)*10) %>%
  group_by(age_decile) %>%
  summarize(sample_size=n(),mean(abs_error), frac_overest = mean(overest))

res_general %>%
  group_by(p_charge) %>%
  summarize(sample_size=n(),mean(abs_error), frac_overest = mean(overest))
```

```{r}
### People with largest errors
thresh = quantile(res_general$abs_error, probs = .90)
res_general_worst = res_general %>%
  filter(abs_error > thresh)

print(paste("Fraction overestimated =",round(mean(res_general_worst$overest),2)))
print(paste("Ratio African-American / Caucasian =",round(sum(res_general_worst$race=="African-American") / sum(res_general_worst$race=="Caucasian"),2)))
print(paste("Ratio Men / Women =",round(sum(res_general_worst$sex=="Male") / sum(res_general_worst$sex=="Female"),2)))

res_general_worst %>%
  group_by(sex) %>%
  summarize(sample_size=n(),mean(abs_error), frac_overest = mean(overest))

res_general_worst %>%
  group_by(race) %>%
  summarize(sample_size=n(),mean(abs_error), frac_overest = mean(overest))

res_general_worst %>%
  mutate(age_decile = floor(p_current_age/10)*10) %>%
  group_by(age_decile) %>%
  summarize(sample_size=n(),mean(abs_error), frac_overest = mean(overest))

res_general_worst %>%
  group_by(p_charge) %>%
  summarize(sample_size=n(),mean(abs_error), frac_overest = mean(overest))
```

```{r}
### Variable importance
importance_matrix <- xgb.importance(model = md_general)
xgb.plot.importance(importance_matrix = importance_matrix)
```

```{r}
plot(res_violent$error, res_general$error)
```

```{r}
pid_select = c(8512)

View(filter(people_df, person_id %in% pid_select))
View(filter(casearrest_df, person_id %in% pid_select))
View(filter(charge_df, person_id %in% pid_select))
View(filter(jailhistory_df, person_id %in% pid_select))
View(filter(prisonhistory_df, person_id %in% pid_select))
```
